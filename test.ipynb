{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bericht Projektlabor Maschinelles Lernen (PML)\n",
    "\n",
    "|Gruppenmitglied|Matrikelnummer|\n",
    "|---|---|\n",
    "|Christian Singer|?|\n",
    "|Domenic Gosein|002160647|\n",
    "|Lukas Burger|?|\n",
    "|Christian Singer|2161064|\n",
    "|Domenic Gosein|2160647|\n",
    "|Lukas Burger|2150580|\n",
    "|Maximilian Kürschner|2160331|\n",
    "\n",
    "Dozent: Dr.-Ing. Wei Yap Tan  \n",
    "\n",
    "Fakultät der Informationstechnik  \n",
    "\n",
    "Hochschule Mannheim  \n",
    "Wintersemester 2021/22  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inhalt\n",
    "\n",
    "1. Einleitung\n",
    "2. Kalman Filter für den 1D Radarsensor\n",
    "3. Experiment für den 1D Radarsensor\n",
    "4. DBSCAN für den 3D Radarsensor\n",
    "5. Kalman Filter für den 3D Radarsensor\n",
    "6. Experiment für den 3D Radarsensor\n",
    "7. Schlussfolgerung\n",
    "8. Ausblick\n",
    "9. Verwendete Literatur\n",
    "10. Anhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einleitung\n",
    "\n",
    "Nach einer Einführung in maschinelles Lernen, war es unsere Aufgabe das Kalman Filter und den DBSCAN Algorithmus für Daten aus einem 1D und anschließend 3D Radarsensor zu implementieren.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folgender Code muss zu Beginn des Notebooks ausgeführt werden,\n",
    "# er importiert alle notwendigen Bibliotheken.\n",
    "# Import aller benötigten Module\n",
    "# Eigene Module\n",
    "from DataGenerationRadar3D import *\n",
    "from DBScan import *\n",
    "from Widgets3D import *\n",
    "# Externe Module\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import copy\n",
    "from collections import deque\n",
    "\n",
    "from ipywidgets import interact, interactive, interactive_output, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Radarsensor\n",
    "Um ein besseres Verständis für das Kalman Filter zu erlangen, haben wir uns zunächst mit der Theorie dahinter beschäftigt. Im Zuge dieses Prozesses sind wir auf den --Filter gestoßen. Der -\n",
    "\n",
    "In diesem Abschnitt befinden sich Simulation, Kalman Filter und Experiment für den 1D Radarsensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D-Radar-Sensor Simulation\n",
    "-Filter bildet die Grundlage für eine Reihe von Filtern, darunter auch das Kalman Filter. Wir haben uns daher dazu entschlossen, diesen zu Übungszwecken zu implementiert.\n",
    "\n",
    "Die Simulation für den 1D Radarsensor gibt uns die Wahl zwischen fünf verschiedenen Bewegungsarten: Static, Constant Velocity, Constant Acceleration, Sinus und Triangle, sowie die Möglichkeit einen Sporadic Error zu den Sensordaten hinzuzufügen.  \n",
    "Zudem lassen sich an dieser Stelle die Sensor Eigenschaften anspassen."
    "In unserem Beispiel verwenden wir den Filter dazu, das Körpergewicht einer Person vorherzusagen.\n",
    "\n",
    "Unser Filter verwendet dazu folgende Parameter:\n",
    "\n",
    "    x_0 als initialen Zusatandswert (in unserem Fall das Anfangsgewicht)\n",
    "    dx als initiale Änderungsrate des Gewichts z. B. +0.5 kg/Tag\n",
    "    a als Faktor für die Veränderung der Gewichtsmessung\n",
    "    b als Faktor für die Änderungsrate des Gewichts\n",
    "    dt für das Zeitintervall\n",
    "\n",
    "sowie values für unsere Messwerte.\n",
    "\n",
    "Nachdem der\n",
    "-\n",
    "\n",
    "-Filter initialisiert wurde, führt er folgende Schritte aus:\n",
    "\n",
    "    Berechnung der Vorhersage im nächsten Zeitintervall basierend auf aktuellem Schätzwert, Änderungsrate und Zeitintervall\n",
    "    Berechnen der Differenz aus aktuellem Messwert und Vorhersage\n",
    "    Anpassung der neuen Änderungsrate mit Faktor b, des Restwerts aus Schritt 2 und dem Zeitintervall\n",
    "    Berechnung des neuen Schätzwerts mittels Vorhersage, Faktor a und Restwert\n",
    "\n",
    "Um den Filter zu testen haben wir mittels einer Funktion 14 Messwerte generiert und diese an den Filter übergeben. Zur Initialisierung haben wir zudem 86 kg, einen Änderungsrate von +1 kg/Tag, einen\n",
    "-Wert von 0.4 und einen -Wert von 0.2 und einen Zeitintervall von 1 übergeben. Auf passende Werte für a und b sind wir durch ausprobieren gestoßen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minRange = 0.3  # m\n",
    "maxRange = 25.0  # m\n",
    "maxVelocity = 25  # m/s --> 90 km/h\n",
    "rangeAccuracy = 0.02  # m\n",
    "velocityAccuracy = 0.005  # m/s\n",
    "measurementRate = 100  # Hz"
    "class abFilter:\n",
    "    def __init__(self, x_0, dx, a, b, dt):\n",
    "        self.x_est = x_0 # initial state value\n",
    "        self.dx = dx # inital change rate\n",
    "        self.a = a # a scale factor\n",
    "        self.b = b # b scale factor\n",
    "        self.dt = dt # time step\n",
    "    \n",
    "    def step(self, values):\n",
    "        ests = []\n",
    "        preds = []\n",
    "        for z in values:\n",
    "            # Predict\n",
    "            x_pred = self.x_est + (self.dx * self.dt)\n",
    "            preds.append(x_pred)\n",
    "            self.dx = self.dx\n",
    "            # Update\n",
    "            residual = z - x_pred\n",
    "            self.dx += self.b * (residual)/self.dt\n",
    "            self.x_est = x_pred + self.a * residual\n",
    "            ests.append(self.x_est)\n",
    "        return np.array(ests), np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateData(type=\"Static\", options={}):\n",
    "\n",
    "    # static\n",
    "    if(type == \"Static\"):\n",
    "        # sanity check\n",
    "        if((\"initialDistance\" in options) == False) \\\n",
    "                or ((\"stopTime\" in options) == False):\n",
    "            return None, None\n",
    "\n",
    "        timeAxis = np.arange(0, options[\"stopTime\"], 0.01/measurementRate)\n",
    "        distValues = options[\"initialDistance\"] * \\\n",
    "            np.ones(np.shape(timeAxis))\n",
    "        truthDistValues = copy.copy(distValues)\n",
    "\n",
    "        distValues += np.random.uniform(-1*rangeAccuracy,\n",
    "                                           rangeAccuracy, np.shape(timeAxis))\n",
    "        velValues = np.zeros(np.shape(timeAxis))\n",
    "        truthVelValues = copy.copy(velValues)\n",
    "\n",
    "        velValues += np.random.uniform(-1*velocityAccuracy,\n",
    "                                          velocityAccuracy, np.shape(timeAxis))\n",
    "        velValues[distValues > maxRange] = np.NaN\n",
    "        distValues[distValues > maxRange] = np.NaN\n",
    "        velValues[distValues < minRange] = np.NaN\n",
    "        distValues[distValues < minRange] = np.NaN        \n",
    "        velValues[velValues > maxVelocity] = np.NaN\n",
    "        velValues[velValues < -1 * maxVelocity] = np.NaN\n",
    "\n",
    "        # decimate to actual measurement rate\n",
    "        timeAxis = timeAxis[0::100]\n",
    "        distValues = distValues[0::100]\n",
    "        velValues = velValues[0::100]\n",
    "        truthDistValues = truthDistValues[0::100]\n",
    "        truthVelValues = truthVelValues[0::100]\n",
    "    \n",
    "        if(\"SporadicError\" in options):\n",
    "            rng = np.random.default_rng()\n",
    "            ind = rng.choice(np.size(timeAxis), size=options[\"SporadicError\"], replace=False)\n",
    "\n",
    "            distValues[ind] = np.random.uniform(minRange,\n",
    "                                           maxRange, np.shape(ind))\n",
    "\n",
    "            velValues[ind] = np.random.uniform(-1*maxVelocity,\n",
    "                                           maxVelocity, np.shape(ind))\n",
    "\n",
    "        return timeAxis, distValues, velValues, truthDistValues, truthVelValues\n",
    "\n",
    "    # constant velocity\n",
    "    if(type == \"ConstantVelocity\"):\n",
    "        # sanity check\n",
    "        if((\"initialDistance\" in options) == False) \\\n",
    "                or ((\"stopTime\" in options) == False) \\\n",
    "                or ((\"velocity\" in options) == False):\n",
    "            return None, None\n",
    "\n",
    "        timeAxis = np.arange(0, options[\"stopTime\"], 0.01/measurementRate)\n",
    "\n",
    "        distValues = options[\"initialDistance\"] + options[\"velocity\"]*timeAxis\n",
    "        truthDistValues = copy.copy(distValues)\n",
    "\n",
    "        distValues += np.random.uniform(-1*rangeAccuracy,\n",
    "                                           rangeAccuracy, np.shape(timeAxis))\n",
    "\n",
    "        velValues = options[\"velocity\"] * np.ones(np.shape(timeAxis))\n",
    "        truthVelValues = copy.copy(velValues)\n",
    "\n",
    "        velValues += np.random.uniform(-1*velocityAccuracy,\n",
    "                                          velocityAccuracy, np.shape(timeAxis))\n",
    "        velValues[distValues > maxRange] = np.NaN\n",
    "        distValues[distValues > maxRange] = np.NaN\n",
    "        velValues[distValues < minRange] = np.NaN\n",
    "        distValues[distValues < minRange] = np.NaN\n",
    "        velValues[velValues > maxVelocity] = np.NaN\n",
    "        velValues[velValues < -1 * maxVelocity] = np.NaN\n",
    "        \n",
    "        # decimate to actual measurement rate\n",
    "        timeAxis = timeAxis[0::100]\n",
    "        distValues = distValues[0::100]\n",
    "        velValues = velValues[0::100]\n",
    "        truthDistValues = truthDistValues[0::100]\n",
    "        truthVelValues = truthVelValues[0::100]\n",
    "    \n",
    "        if(\"SporadicError\" in options):\n",
    "            rng = np.random.default_rng()\n",
    "            ind = rng.choice(np.size(timeAxis), size=options[\"SporadicError\"], replace=False)\n",
    "\n",
    "            distValues[ind] = np.random.uniform(minRange,\n",
    "                                           maxRange, np.shape(ind))\n",
    "\n",
    "            velValues[ind] = np.random.uniform(-1*maxVelocity,\n",
    "                                           maxVelocity, np.shape(ind))\n",
    "\n",
    "        return timeAxis, distValues, velValues\n",
    "\n",
    "    # constant acceleration\n",
    "    if(type == \"ConstantAcceleration\"):\n",
    "        # sanity check\n",
    "        if((\"initialDistance\" in options) == False) \\\n",
    "                or ((\"stopTime\" in options) == False) \\\n",
    "                or ((\"initialVelocity\" in options) == False) \\\n",
    "                or ((\"acceleration\" in options) == False):\n",
    "            return None, None\n",
    "\n",
    "        timeAxis = np.arange(0, options[\"stopTime\"], 0.01/measurementRate)\n",
    "\n",
    "        velValues = options[\"initialVelocity\"] + \\\n",
    "            options[\"acceleration\"] * timeAxis\n",
    "        distValues = options[\"initialDistance\"] + 0.5 * \\\n",
    "            options[\"acceleration\"] * timeAxis * timeAxis\n",
    "\n",
    "        truthVelValues = copy.copy(velValues)\n",
    "        truthDistValues = copy.copy(distValues)\n",
    "\n",
    "        velValues += np.random.uniform(-1*velocityAccuracy,\n",
    "                                          velocityAccuracy, np.shape(timeAxis))\n",
    "        distValues += np.random.uniform(-1*rangeAccuracy,\n",
    "                                           rangeAccuracy, np.shape(timeAxis))\n",
    "\n",
    "        velValues[distValues > maxRange] = np.NaN\n",
    "        distValues[distValues > maxRange] = np.NaN\n",
    "        velValues[distValues < minRange] = np.NaN\n",
    "        distValues[distValues < minRange] = np.NaN\n",
    "        velValues[velValues > maxVelocity] = np.NaN\n",
    "        velValues[velValues < -1 * maxVelocity] = np.NaN\n",
    "        \n",
    "        # decimate to actual measurement rate\n",
    "        timeAxis = timeAxis[0::100]\n",
    "        distValues = distValues[0::100]\n",
    "        velValues = velValues[0::100]\n",
    "        truthDistValues = truthDistValues[0::100]\n",
    "        truthVelValues = truthVelValues[0::100]\n",
    "    \n",
    "        if(\"SporadicError\" in options):\n",
    "            rng = np.random.default_rng()\n",
    "            ind = rng.choice(np.size(timeAxis), size=options[\"SporadicError\"], replace=False)\n",
    "\n",
    "            distValues[ind] = np.random.uniform(minRange,\n",
    "                                           maxRange, np.shape(ind))\n",
    "\n",
    "            velValues[ind] = np.random.uniform(-1*maxVelocity,\n",
    "                                           maxVelocity, np.shape(ind))\n",
    "\n",
    "        return timeAxis, distValues, velValues, truthDistValues, truthVelValues\n",
    "\n",
    "    # sinus movement\n",
    "    if(type == \"Sinus\"):\n",
    "        # sanity check\n",
    "        if((\"initialDistance\" in options) == False) \\\n",
    "                or ((\"stopTime\" in options) == False) \\\n",
    "                or ((\"movementRange\" in options) == False) \\\n",
    "                or ((\"frequency\" in options) == False):\n",
    "            return None, None\n",
    "\n",
    "        timeAxis = np.arange(0, options[\"stopTime\"], 0.01/measurementRate)\n",
    "\n",
    "        distValues = options[\"initialDistance\"] + options[\"movementRange\"] * \\\n",
    "            np.sin(2*np.pi*options[\"frequency\"]*timeAxis)\n",
    "\n",
    "        truthDistValues = copy.copy(distValues)\n",
    "\n",
    "        velValues = 2*np.pi*options[\"frequency\"] * options[\"movementRange\"] * np.cos(\n",
    "            2*np.pi*options[\"frequency\"]*timeAxis)\n",
    "\n",
    "        truthVelValues = copy.copy(velValues)\n",
    "\n",
    "        velValues += np.random.uniform(-1*velocityAccuracy,\n",
    "                                          velocityAccuracy, np.shape(timeAxis))\n",
    "        distValues += np.random.uniform(-1*rangeAccuracy,\n",
    "                                           rangeAccuracy, np.shape(timeAxis))\n",
    "\n",
    "        velValues[distValues > maxRange] = np.NaN\n",
    "        distValues[distValues > maxRange] = np.NaN\n",
    "        velValues[distValues < minRange] = np.NaN\n",
    "        distValues[distValues < minRange] = np.NaN\n",
    "        velValues[velValues > maxVelocity] = np.NaN\n",
    "        velValues[velValues < -1 * maxVelocity] = np.NaN\n",
    "        \n",
    "        # decimate to actual measurement rate\n",
    "        timeAxis = timeAxis[0::100]\n",
    "        distValues = distValues[0::100]\n",
    "        velValues = velValues[0::100]\n",
    "        truthDistValues = truthDistValues[0::100]\n",
    "        truthVelValues = truthVelValues[0::100]\n",
    "    \n",
    "        if(\"SporadicError\" in options):\n",
    "            rng = np.random.default_rng()\n",
    "            ind = rng.choice(np.size(timeAxis), size=options[\"SporadicError\"], replace=False)\n",
    "\n",
    "            distValues[ind] = np.random.uniform(minRange,\n",
    "                                           maxRange, np.shape(ind))\n",
    "\n",
    "            velValues[ind] = np.random.uniform(-1*maxVelocity,\n",
    "                                           maxVelocity, np.shape(ind))\n",
    "\n",
    "        return timeAxis, distValues, velValues, truthDistValues, truthVelValues\n",
    "\n",
    "    # triangle movement\n",
    "    if(type == \"Triangle\"):\n",
    "        # sanity check\n",
    "        if((\"initialDistance\" in options) == False) \\\n",
    "                or ((\"stopTime\" in options) == False) \\\n",
    "                or ((\"movementRange\" in options) == False) \\\n",
    "                or ((\"frequency\" in options) == False):\n",
    "            return None, None\n",
    "\n",
    "        timeAxis = np.arange(0, options[\"stopTime\"], 0.01/measurementRate)\n",
    "\n",
    "        distValues = np.zeros(np.shape(timeAxis))\n",
    "        velValues = np.zeros(np.shape(timeAxis))\n",
    "\n",
    "        for i in range(np.size(timeAxis)):\n",
    "            t = timeAxis[i]\n",
    "            while (t > 1/options[\"frequency\"]):\n",
    "                t = t - 1/options[\"frequency\"]\n",
    "\n",
    "            if (t <= 1/(2*options[\"frequency\"])):\n",
    "                if(i == 0):\n",
    "                    distValues[i] = options[\"initialDistance\"] + (2 * options[\"frequency\"] * options[\"movementRange\"])*0.01/measurementRate\n",
    "                else:\n",
    "                    distValues[i] = distValues[i-1] + (2 * options[\"frequency\"] * options[\"movementRange\"])*0.01/measurementRate\n",
    "                \n",
    "                velValues[i] = 2 * options[\"frequency\"] * options[\"movementRange\"]   \n",
    "            else:\n",
    "                distValues[i] = distValues[i-1] - (2 * options[\"frequency\"] * options[\"movementRange\"])*0.01/measurementRate\n",
    "                velValues[i] = -2 * options[\"frequency\"] * options[\"movementRange\"]   \n",
    "\n",
    "        truthDistValues = copy.copy(distValues)\n",
    "        truthVelValues = copy.copy(velValues)\n",
    "\n",
    "        velValues += np.random.uniform(-1*velocityAccuracy,\n",
    "                                          velocityAccuracy, np.shape(timeAxis))\n",
    "        distValues += np.random.uniform(-1*rangeAccuracy,\n",
    "                                           rangeAccuracy, np.shape(timeAxis))\n",
    "\n",
    "        velValues[distValues > maxRange] = np.NaN\n",
    "        distValues[distValues > maxRange] = np.NaN\n",
    "        velValues[distValues < minRange] = np.NaN\n",
    "        distValues[distValues < minRange] = np.NaN\n",
    "        velValues[velValues > maxVelocity] = np.NaN\n",
    "        velValues[velValues < -1 * maxVelocity] = np.NaN\n",
    "        # decimate to actual measurement rate\n",
    "        timeAxis = timeAxis[0::100]\n",
    "        distValues = distValues[0::100]\n",
    "        velValues = velValues[0::100]\n",
    "        truthDistValues = truthDistValues[0::100]\n",
    "        truthVelValues = truthVelValues[0::100]\n",
    "    \n",
    "        if(\"SporadicError\" in options):\n",
    "            rng = np.random.default_rng()\n",
    "            ind = rng.choice(np.size(timeAxis), size=options[\"SporadicError\"], replace=False)\n",
    "\n",
    "            distValues[ind] = np.random.uniform(minRange,\n",
    "                                           maxRange, np.shape(ind))\n",
    "\n",
    "            velValues[ind] = np.random.uniform(-1*maxVelocity,\n",
    "                                           maxVelocity, np.shape(ind))\n",
    "\n",
    "        return timeAxis, distValues, velValues, truthDistValues, truthVelValues\n",
    "\n",
    "    else:\n",
    "        return 0, 0"
    "# Daten: Körpergewichte über n Tage verteilt gemessen\n",
    "count = 28\n",
    "def data_generator(x_0, dx, count, noise_factor):\n",
    "    return [x_0 + dx * i + np.random.randn() * noise_factor for i in range(count)]\n",
    "\n",
    "gewichte = data_generator(79.9, 0.4, count, 0.3) # kg\n",
    "#print(gewichte)\n",
    "zeitabstaende = [i for i in range(28)] # n Tage\n",
    "print()\n",
    "# Initialisierung und Ausführung des ab-Filters\n",
    "gewicht_filter = abFilter(x_0=86, dx=1, a=0.4, b=0.2, dt=1.)\n",
    "pr = gewicht_filter.step(values=gewichte)\n",
    "\n",
    "# Ploten der Filter Ergebnisse im Vergleich zu den den echten Werten\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "ax.plot(pr[0], label='Filter Est')\n",
    "ax.plot(pr[1], label='Filter Pred', color='r')\n",
    "ax.scatter(zeitabstaende, gewichte, s=50, facecolor='C1', edgecolor='k', label='Messwerte')\n",
    "ax.plot([0,count], [80., 91.], label='Tatsächliches Gewicht', linestyle='--', color='grey')\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('kg')\n",
    "ax.set_title(\"ab-Filter\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q Matrix Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros, vstack, eye, array\n",
    "from numpy.linalg import inv\n",
    "from scipy.linalg import expm, block_diag\n",
    "\n",
    "def order_by_derivative(Q, dim, block_size):\n",
    "    N = dim * block_size\n",
    "\n",
    "    D = zeros((N, N))\n",
    "\n",
    "    Q = array(Q)\n",
    "    for i, x in enumerate(Q.ravel()):\n",
    "        f = eye(block_size) * x\n",
    "\n",
    "        ix, iy = (i // dim) * block_size, (i % dim) * block_size\n",
    "        D[ix:ix+block_size, iy:iy+block_size] = f\n",
    "\n",
    "    return D\n",
    "\n",
    "def Q_discrete_white_noise(dim, dt=1., var=1., block_size=1, order_by_dim=True):\n",
    "    if dim not in [2, 3, 4]:\n",
    "        raise ValueError(\"dim must be between 2 and 4\")\n",
    "\n",
    "    if dim == 2:\n",
    "        Q = [[.25*dt**4, .5*dt**3],\n",
    "             [ .5*dt**3,    dt**2]]\n",
    "    elif dim == 3:\n",
    "        Q = [[.25*dt**4, .5*dt**3, .5*dt**2],\n",
    "             [ .5*dt**3,    dt**2,       dt],\n",
    "             [ .5*dt**2,       dt,        1]]\n",
    "    else:\n",
    "        Q = [[(dt**6)/36, (dt**5)/12, (dt**4)/6, (dt**3)/6],\n",
    "             [(dt**5)/12, (dt**4)/4,  (dt**3)/2, (dt**2)/2],\n",
    "             [(dt**4)/6,  (dt**3)/2,   dt**2,     dt],\n",
    "             [(dt**3)/6,  (dt**2)/2 ,  dt,        1.]]\n",
    "\n",
    "    if order_by_dim:\n",
    "        return block_diag(*[Q]*block_size) * var\n",
    "    return order_by_derivative(array(Q), dim, block_size) * var\n",
    "\n",
    "# Q_discrete_white_noise(dim=3, dt=1., var=0.01)"
    "Die von uns gewählte initiale Schätzung von 86 kg war mit Absicht sehr hoch gewählt. Wir sehen daher einen großen Ausschlag zu Beginn, schließlich benötigt der Filter einige Iterationen, um sein Werte anzupassen, so dass der Filter zum Ende hin eine deutlich bessere Schätzung ausgiebt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Filter für den 1D Radarsensor\n",
    "## Kalman Filter\n",
    "\n",
    "Das Kalman Filter ist ein Algorithmus, der anhand einer Reihe von Messungen über eine gewisse Zeit unbekannte Variablenwerte eines Systems schätzt. Dabei versucht das Filter Unsicherheiten durch statistisches Rauschen und den Einbezug eines zu Grunde liegenden physiklasichen Modells zu reduzieren.\n",
    "\n",
    "In unserem Fall versuchen wir mit das Kalman Filter die Position eines Objekts erst im eindimensionalen Raum, dann in einem dreidimensionalen Raum vorherzusagen,. Die Messwerte liefert uns dabei eine Radarsensor Simulation.\n",
    "\n",
    "Die Klasse KalmanFilter implementiert das Kalman Filter und besteht aus zwei Methoden. Über die __init__(self, s_hat, transition_model, H, Q, R) Methode kann das Kalman Filter mit folgenden Parametern initialisiert werden:\n",
    "\n",
    "Die Klasse des Kalman Filter besteht aus zwei Funktionen, einer`__init__` Funktion zur Initialisierung der Klasse und einer `step` Funktion, die den Kalman Algorithmus implementiert."
    "    s_hat ist die Position des Objekts im Raum (x, y, z Koordianten)\n",
    "    P_hat ist die Kovarianz des Zustands\n",
    "    model/transition_model ist das zu Grunde liegene physikalische Modell\n",
    "    H ist die Messfunktion\n",
    "    Q beschreibt das Prozessrauschen\n",
    "    R beschreibt das Messrauschen\n",
    "\n",
    "Nach der Initialisierung kann die step(self,z) Funktion mit den Messwerten z aufgerufen werden, um den Kalman Algorithmus auszuführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter:\n",
    "    # Initialisierung von Kalman Filter\n",
    "    def __init__(self, s_hat, transition_model, H, Q, R):\n",
    "        self.s_hat = s_hat\n",
    "        self.P_hat = np.eye(len(s_hat)) * 100\n",
    "        self.model = transition_model\n",
    "        self.H = H # Measurement Function\n",
    "        self.Q = Q # Process Noise\n",
    "        self.R = R # Measurement Noise.\n",
    "        pass\n",
    "\n",
    "    def step(self,z):\n",
    "    \n",
    "    def step(self, z):\n",
    "        # Prediction\n",
    "        s_hat_p = self.model @ self.s_hat\n",
    "        P_hat_p = self.model @ self.P_hat @ self.model.T +  self.Q\n",
    "        # Calculate Kalman Matrix\n",
    "        P_hat_p = self.model @ self.P_hat @ self.model.T + self.Q\n",
    "        # Calculate Kalman Gain\n",
    "        K = P_hat_p @ self.H.T @ np.linalg.inv(self.H @ P_hat_p @ self.H.T + self.R)\n",
    "        # Update covariance of estimation error\n",
    "        self.P_hat = self.P_hat - K @ self.H @ self.P_hat\n",
    "        # Improve estimate\n",
    "        e_m_p = z - self.H @ s_hat_p\n",
    "        self.s_hat = s_hat_p + K @ e_m_p\n",
    "        return self.s_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Detail führt die step(self,z) Methode dann folgende Schritte nacheinander aus:\n",
    "\n",
    "    Vorhersage der neuen Position durch s_hat_p = self.model @ self.s_hat\n",
    "    Berechnung der Kovarianz des Zustands durch P_hat_p = self.model @ self.P_hat @ self.model.T + self.Q\n",
    "    Berechung des Kalman Gain durch K = P_hat_p @ self.H.T @ np.linalg.inv(self.H @ P_hat_p @ self.H.T + self.R)\n",
    "    Aktualisierung der Kovarianz des Zustands durch self.P_hat = self.P_hat - K @ self.H @ self.P_hat\n",
    "    Verbesserung der Schätzung durch e_m_p = z - self.H @ s_hat_p und self.s_hat = s_hat_p + K @ e_m_p\n",
    "\n",
    "Zum Schluss wird die neu geschätzte Position zurückgegeben.\n",
    "\n",
    "Um den Filter zu testen, initialisieren wir ihn mit folgenden Werten für transition_model, Q, H, R:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Radarsensor\n",
    "\n",
    "In diesem Abschnitt befinden sich Simulation, Kalman Filter und Experiment für den 1D Radarsensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D-Radar-Sensor Simulation\n",
    "\n",
    "Die Simulation für den 1D Radarsensor gibt uns die Wahl zwischen fünf verschiedenen Bewegungsarten: Static, Constant Velocity, Constant Acceleration, Sinus und Triangle, sowie die Möglichkeit einen Sporadic Error zu den Sensordaten hinzuzufügen.  \n",
    "Zudem lassen sich an dieser Stelle die Sensor Eigenschaften anspassen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment für den 1D Radarsensor\n",
    "\n",
    "In unserem Experiment für die Daten aus dem eindimensionalen Radarsensor haben wir nachfolgend alle Bewegungsarten simuliert und an das Kalman Filter übergeben.\n",
    "\n",
    "#### Verhalten und Beschreibung für Static\n",
    "\n",
    "![1DExpStatic](RadarSensor1D/1DExpStatic.png)\n",
    "\n",
    "#### Verhalten und Beschreibung für Static mit Sporadic Error\n",
    "\n",
    "![1DExpStaticEr](RadarSensor1D/1DExpStaticEr.png)\n",
    "\n",
    "#### Verhalten und Beschreibung für ..\n",
    "\n",
    "\n",
    "\n",
    "#### Verhalten und Beschreibung für .. mit Sporadic Error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn das Jupyter Notebook ausgeführt wird, können die nachfolgenden Parameter beliebig angepasst werden, um eine Simulation mit dem Kalman Filter auszuprobieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionen für die Simulation\n",
    "opt = {\n",
    "    \"initialDistance\": 8,\n",
    "    \"stopTime\": 1,\n",
    "    # \"velocity\": 3,\n",
    "\n",
    "1. Kalman and Bayesian Filters in Python, 2015, Roger R. Labbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_model = np.array([[1, 0.01, 0.01/2],\n",
    "                             [0, 1,    0.01  ],\n",
    "                             [0, 0,    0.01 ]])\n",
    "Q = np.diag([0.05, 0.05, 0.05])\n",
    "H =  np.array([[1., 0., 0.]])\n",
    "R = np.diag([rangeAccuracy**2])/3\n",
    "\n",
    "\n",
    "path1 = [[0,   5, 0  ],\n",
    "         [0,   5, 0.5],\n",
    "         [1,   4, 1  ],\n",
    "         [2,   3, 2  ],\n",
    "         [1,   5, 3  ],\n",
    "         [1,   5, 0.5],\n",
    "         [0.5, 2, 0.1]]\n",
    "\n",
    "vel1 = 3 * np.ones((1,len(path1)))\n",
    "vel1[0,2] = 1\n",
    "\n",
    "InitialPosition1 = np.array([-1,5,0])\n",
    "\n",
    "opt1 = {\n",
    "    'InitialPosition' : InitialPosition1,\n",
    "    'Path' : np.array(path1).transpose(),\n",
    "    'Velocities' : vel1\n",
    "}\n",
    "\n",
    "x = Target(opt1)\n",
    "\n",
    "targets = [x]\n",
    "\n",
    "\n",
    "\n",
    "optRadar = {\n",
    "    'Position' : np.array([0, 0, 0.5]),\n",
    "    'OpeningAngle' : np.array([120,90]), # [Horizontal, Vertical]\n",
    "    'FalseDetection': True\n",
    "}\n",
    "sensor = RadarSensor(optRadar)\n",
    "\n",
    "\n",
    "\n",
    "Detections = np.array([0,0,0])\n",
    "model = DBSCAN(eps=0.2, minpts=2)\n",
    "# Number of previous measurements to consider for DBSCAN().\n",
    "ante = 20\n",
    "# Count number of iterations\n",
    "i = 0\n",
    "\n",
    "getNext = True\n",
    "while(getNext == True):\n",
    "    i += 1\n",
    "    for target in targets:\n",
    "        target.Step(1/sensor.opt['MeasurementRate'])\n",
    "        getNext = getNext & ~target.reachedEnd  \n",
    "\n",
    "    dets = sensor.Detect(targets)\n",
    "    # Exclude radialVelocity for the moment. (todo: include it.)\n",
    "    for det in dets:\n",
    "        det = det[:-1]\n",
    "        Detections = np.vstack((det, Detections))\n",
    "    \n",
    "    s0 = np.vstack((Detections[0,:-1], np.zeros((2,3))))\n",
    "    f = KalmanFilter(s0, transition_model, H, Q, R))\n",
    "    \n",
    "    for \n",
    "    s = Detections[0,:-1].reshape(1,3)\n",
    "    s_hat = f.step(s)\n",
    "    pred = np.vstack((s_hat[0,:], pred))\n",
    "    \n",
    "    \n",
    "    # Execute once to initialize filters etc. todo: Is there a smarter way to do all below ?\n",
    "    if i == ante:\n",
    "        # First application of DBSCAN.\n",
    "        clusters = model.fit_predict(Detections[:ante])\n",
    "        # Determine number of targets (objects tracked).\n",
    "        num_objs = len(set(clusters[clusters > -1]))\n",
    "        \n",
    "        # \"Filters\" contains a kalman filter for each target.\n",
    "        Filters = []\n",
    "        # \"Preds\" contains the predictions of the path of each target.\n",
    "        Preds = []\n",
    "        # Iterate over the targets.\n",
    "        for j in range(num_objs):\n",
    "            # Find index of first occurence of target j in clusters.\n",
    "            # This line is needed to filter out false detections\n",
    "            # obj_idx = np.where(clusters == j)[0][0]\n",
    "            # Add placeholder values for speed and acceleration in each component to the detection.\n",
    "            s0 = np.vstack((Detections[obj_idx], np.zeros((2,3))))\n",
    "            Filters.append(KalmanFilter(s0, transition_model, H, Q, R))\n",
    "            # For the moment only the predicted position is relevant. todo: incorporate velocity.\n",
    "            Preds.append(s0[0,:])\n",
    "\n",
    "    # Cluster and predict position via Kalman filter.\n",
    "    elif i > ante:\n",
    "        clusters = model.fit_predict(Detections[:ante])\n",
    "        for j in range(num_objs):\n",
    "            # try/ except prevents non-detection of existing object from breaking the program.\n",
    "            try:\n",
    "                obj_idx = np.where(clusters == j)[0][0]\n",
    "                # Reshape is needed to make matrix multiplication inside the kalman filter work.\n",
    "                s = Detections[obj_idx].reshape(1,3)\n",
    "                s_hat = Filters[j].step(s)\n",
    "                Preds[j] = np.vstack((s_hat[0,:], Preds[j]))\n",
    "            except IndexError:\n",
    "                print(f\"Object {j} not found!\")\n",
    "                continue\n",
    "\n",
    "# Visualize trajectory.\n",
    "T1 = Preds[0][:-1]\n",
    "\n",
    "# Plot Trajectory\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')   \n",
    "#ax.view_init(20, 35) \n",
    "ax.plot3D(T1[:,0], T1[:,1], T1[:,2], 'blue')"
   ]
  }
 ],
 "metadata": {
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
